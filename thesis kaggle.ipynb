{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ***IMPORTING FROM MY GITHUB REPO AND INSTALLING DEPENDENCIES*** #   ","metadata":{}},{"cell_type":"code","source":"!git clone https://github.com/yazdanasadi/MasterThesis-1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T07:57:07.753905Z","iopub.execute_input":"2025-10-17T07:57:07.754470Z","iopub.status.idle":"2025-10-17T07:57:12.467855Z","shell.execute_reply.started":"2025-10-17T07:57:07.754444Z","shell.execute_reply":"2025-10-17T07:57:12.467179Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'MasterThesis-1'...\nremote: Enumerating objects: 439, done.\u001b[K\nremote: Counting objects: 100% (375/375), done.\u001b[K\nremote: Compressing objects: 100% (293/293), done.\u001b[K\nremote: Total 439 (delta 144), reused 303 (delta 81), pack-reused 64 (from 1)\u001b[K\nReceiving objects: 100% (439/439), 106.81 MiB | 40.48 MiB/s, done.\nResolving deltas: 100% (148/148), done.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"%cd /kaggle/working/MasterThesis-1/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T07:57:12.469344Z","iopub.execute_input":"2025-10-17T07:57:12.469617Z","iopub.status.idle":"2025-10-17T07:57:12.475046Z","shell.execute_reply.started":"2025-10-17T07:57:12.469581Z","shell.execute_reply":"2025-10-17T07:57:12.474307Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/MasterThesis-1\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!rm -rf /kaggle/working//MasterThesis-1/data\n\n# unzip \"data.zip\" \n!unzip -q /kaggle/working/MasterThesis-1/data.zip -d /kaggle/working/MasterThesis-1/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T07:57:12.475705Z","iopub.execute_input":"2025-10-17T07:57:12.475918Z","iopub.status.idle":"2025-10-17T07:57:19.187984Z","shell.execute_reply.started":"2025-10-17T07:57:12.475865Z","shell.execute_reply":"2025-10-17T07:57:19.187201Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"!pip install --upgrade pip\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T07:57:19.189722Z","iopub.execute_input":"2025-10-17T07:57:19.189963Z","iopub.status.idle":"2025-10-17T07:57:24.833372Z","shell.execute_reply.started":"2025-10-17T07:57:19.189937Z","shell.execute_reply":"2025-10-17T07:57:24.832680Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\nCollecting pip\n  Downloading pip-25.2-py3-none-any.whl.metadata (4.7 kB)\nDownloading pip-25.2-py3-none-any.whl (1.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pip\n  Attempting uninstall: pip\n    Found existing installation: pip 24.1.2\n    Uninstalling pip-24.1.2:\n      Successfully uninstalled pip-24.1.2\nSuccessfully installed pip-25.2\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"!pip install -r kaggle-requirements.txt --upgrade \n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T07:57:24.834243Z","iopub.execute_input":"2025-10-17T07:57:24.834444Z"}},"outputs":[{"name":"stdout","text":"Collecting mlflow-skinny==3.4.0 (from -r kaggle-requirements.txt (line 6))\n  Downloading mlflow_skinny-3.4.0-py3-none-any.whl.metadata (31 kB)\nCollecting optuna==3.6.1 (from -r kaggle-requirements.txt (line 7))\n  Downloading optuna-3.6.1-py3-none-any.whl.metadata (17 kB)\nRequirement already satisfied: torchinfo==1.8.0 in /usr/local/lib/python3.11/dist-packages (from -r kaggle-requirements.txt (line 8)) (1.8.0)\nCollecting geotorch==0.3.0 (from -r kaggle-requirements.txt (line 9))\n  Downloading geotorch-0.3.0-py3-none-any.whl.metadata (14 kB)\nCollecting reformer-pytorch==1.4.4 (from -r kaggle-requirements.txt (line 10))\n  Downloading reformer_pytorch-1.4.4-py3-none-any.whl.metadata (764 bytes)\nCollecting stribor==0.1.0 (from -r kaggle-requirements.txt (line 11))\n  Downloading stribor-0.1.0-py3-none-any.whl.metadata (3.0 kB)\nCollecting local-attention==1.9.0 (from -r kaggle-requirements.txt (line 12))\n  Downloading local_attention-1.9.0-py3-none-any.whl.metadata (682 bytes)\nCollecting product-key-memory==0.1.10 (from -r kaggle-requirements.txt (line 13))\n  Downloading product_key_memory-0.1.10.tar.gz (3.5 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting axial-positional-embedding==0.2.1 (from -r kaggle-requirements.txt (line 14))\n  Downloading axial_positional_embedding-0.2.1.tar.gz (2.6 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting protobuf==4.25.3 (from -r kaggle-requirements.txt (line 15))\n  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\nCollecting google-api-core<3.0,>=2.19 (from -r kaggle-requirements.txt (line 16))\n  Downloading google_api_core-2.26.0-py3-none-any.whl.metadata (3.2 kB)\nCollecting google-cloud-bigquery>=3.31.0 (from google-cloud-bigquery[bqstorage,pandas]>=3.31.0->-r kaggle-requirements.txt (line 17))\n  Downloading google_cloud_bigquery-3.38.0-py3-none-any.whl.metadata (8.0 kB)\nCollecting google-cloud-bigquery-storage>=2.30.0 (from -r kaggle-requirements.txt (line 18))\n  Downloading google_cloud_bigquery_storage-2.33.1-py3-none-any.whl.metadata (10 kB)\nCollecting rich==13.7.1 (from -r kaggle-requirements.txt (line 19))\n  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\nCollecting google-cloud-automl>=2.11.0 (from -r kaggle-requirements.txt (line 20))\n  Downloading google_cloud_automl-2.17.0-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: cachetools<7,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.4.0->-r kaggle-requirements.txt (line 6)) (5.5.2)\nRequirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.4.0->-r kaggle-requirements.txt (line 6)) (8.2.1)\nRequirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.4.0->-r kaggle-requirements.txt (line 6)) (3.1.1)\nCollecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==3.4.0->-r kaggle-requirements.txt (line 6))\n  Downloading databricks_sdk-0.68.0-py3-none-any.whl.metadata (39 kB)\nRequirement already satisfied: fastapi<1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.4.0->-r kaggle-requirements.txt (line 6)) (0.115.13)\nRequirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.4.0->-r kaggle-requirements.txt (line 6)) (3.1.44)\nRequirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.4.0->-r kaggle-requirements.txt (line 6)) (8.7.0)\nCollecting opentelemetry-api<3,>=1.9.0 (from mlflow-skinny==3.4.0->-r kaggle-requirements.txt (line 6))\n  Downloading opentelemetry_api-1.38.0-py3-none-any.whl.metadata (1.5 kB)\nCollecting opentelemetry-proto<3,>=1.9.0 (from mlflow-skinny==3.4.0->-r kaggle-requirements.txt (line 6))\n  Downloading opentelemetry_proto-1.38.0-py3-none-any.whl.metadata (2.3 kB)\nCollecting opentelemetry-sdk<3,>=1.9.0 (from mlflow-skinny==3.4.0->-r kaggle-requirements.txt (line 6))\n  Downloading opentelemetry_sdk-1.38.0-py3-none-any.whl.metadata (1.5 kB)\nRequirement already satisfied: packaging<26 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.4.0->-r kaggle-requirements.txt (line 6)) (25.0)\nRequirement already satisfied: pydantic<3,>=1.10.8 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.4.0->-r kaggle-requirements.txt (line 6)) (2.11.7)\nCollecting python-dotenv<2,>=0.19.0 (from mlflow-skinny==3.4.0->-r kaggle-requirements.txt (line 6))\n  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\nRequirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.4.0->-r kaggle-requirements.txt (line 6)) (6.0.2)\nRequirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.4.0->-r kaggle-requirements.txt (line 6)) (2.32.4)\nRequirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.4.0->-r kaggle-requirements.txt (line 6)) (0.5.3)\nRequirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.4.0->-r kaggle-requirements.txt (line 6)) (4.14.0)\nRequirement already satisfied: uvicorn<1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.4.0->-r kaggle-requirements.txt (line 6)) (0.34.3)\nRequirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna==3.6.1->-r kaggle-requirements.txt (line 7)) (1.16.2)\nRequirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna==3.6.1->-r kaggle-requirements.txt (line 7)) (6.9.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna==3.6.1->-r kaggle-requirements.txt (line 7)) (1.26.4)\nRequirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from optuna==3.6.1->-r kaggle-requirements.txt (line 7)) (2.0.41)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna==3.6.1->-r kaggle-requirements.txt (line 7)) (4.67.1)\nRequirement already satisfied: torch>=1.9 in /usr/local/lib/python3.11/dist-packages (from geotorch==0.3.0->-r kaggle-requirements.txt (line 9)) (2.6.0+cu124)\nRequirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from reformer-pytorch==1.4.4->-r kaggle-requirements.txt (line 10)) (0.8.1)\nRequirement already satisfied: pytest in /usr/local/lib/python3.11/dist-packages (from stribor==0.1.0->-r kaggle-requirements.txt (line 11)) (8.3.5)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from stribor==0.1.0->-r kaggle-requirements.txt (line 11)) (1.15.3)\nCollecting torchdiffeq==0.2.1 (from stribor==0.1.0->-r kaggle-requirements.txt (line 11))\n  Downloading torchdiffeq-0.2.1-py3-none-any.whl.metadata (436 bytes)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich==13.7.1->-r kaggle-requirements.txt (line 19)) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich==13.7.1->-r kaggle-requirements.txt (line 19)) (2.19.2)\nRequirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0,>=2.19->-r kaggle-requirements.txt (line 16)) (1.70.0)\nRequirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0,>=2.19->-r kaggle-requirements.txt (line 16)) (1.26.1)\nRequirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0,>=2.19->-r kaggle-requirements.txt (line 16)) (2.40.3)\nRequirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi<1->mlflow-skinny==3.4.0->-r kaggle-requirements.txt (line 6)) (0.46.2)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.4.0->-r kaggle-requirements.txt (line 6)) (4.0.12)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.4.0->-r kaggle-requirements.txt (line 6)) (5.0.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0,>=2.19->-r kaggle-requirements.txt (line 16)) (0.4.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0,>=2.19->-r kaggle-requirements.txt (line 16)) (4.9.1)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.4.0->-r kaggle-requirements.txt (line 6)) (3.23.0)\nINFO: pip is looking at multiple versions of opentelemetry-proto to determine which version is compatible with other requirements. This could take a while.\nCollecting opentelemetry-proto<3,>=1.9.0 (from mlflow-skinny==3.4.0->-r kaggle-requirements.txt (line 6))\n  Downloading opentelemetry_proto-1.37.0-py3-none-any.whl.metadata (2.3 kB)\n  Downloading opentelemetry_proto-1.36.0-py3-none-any.whl.metadata (2.3 kB)\n  Downloading opentelemetry_proto-1.35.0-py3-none-any.whl.metadata (2.3 kB)\n  Downloading opentelemetry_proto-1.34.1-py3-none-any.whl.metadata (2.4 kB)\n  Downloading opentelemetry_proto-1.34.0-py3-none-any.whl.metadata (2.4 kB)\n  Downloading opentelemetry_proto-1.33.1-py3-none-any.whl.metadata (2.4 kB)\n  Downloading opentelemetry_proto-1.33.0-py3-none-any.whl.metadata (2.4 kB)\nINFO: pip is still looking at multiple versions of opentelemetry-proto to determine which version is compatible with other requirements. This could take a while.\n  Downloading opentelemetry_proto-1.32.1-py3-none-any.whl.metadata (2.4 kB)\n  Downloading opentelemetry_proto-1.32.0-py3-none-any.whl.metadata (2.4 kB)\n  Downloading opentelemetry_proto-1.31.1-py3-none-any.whl.metadata (2.4 kB)\n  Downloading opentelemetry_proto-1.31.0-py3-none-any.whl.metadata (2.4 kB)\n  Downloading opentelemetry_proto-1.30.0-py3-none-any.whl.metadata (2.4 kB)\nINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n  Downloading opentelemetry_proto-1.29.0-py3-none-any.whl.metadata (2.3 kB)\n  Downloading opentelemetry_proto-1.28.2-py3-none-any.whl.metadata (2.3 kB)\n  Downloading opentelemetry_proto-1.28.1-py3-none-any.whl.metadata (2.3 kB)\n  Downloading opentelemetry_proto-1.28.0-py3-none-any.whl.metadata (2.3 kB)\n  Downloading opentelemetry_proto-1.27.0-py3-none-any.whl.metadata (2.3 kB)\nCollecting opentelemetry-semantic-conventions==0.59b0 (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.4.0->-r kaggle-requirements.txt (line 6))\n  Downloading opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.4.0->-r kaggle-requirements.txt (line 6)) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.4.0->-r kaggle-requirements.txt (line 6)) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.4.0->-r kaggle-requirements.txt (line 6)) (0.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.4.0->-r kaggle-requirements.txt (line 6)) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.4.0->-r kaggle-requirements.txt (line 6)) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.4.0->-r kaggle-requirements.txt (line 6)) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.4.0->-r kaggle-requirements.txt (line 6)) (2025.6.15)\nRequirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from rsa<5,>=3.1.4->google-auth<3.0.0,>=2.14.1->google-api-core<3.0,>=2.19->-r kaggle-requirements.txt (line 16)) (0.6.1)\nRequirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==3.4.0->-r kaggle-requirements.txt (line 6)) (4.9.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==3.4.0->-r kaggle-requirements.txt (line 6)) (1.3.1)\nRequirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn<1->mlflow-skinny==3.4.0->-r kaggle-requirements.txt (line 6)) (0.16.0)\nRequirement already satisfied: google-cloud-core<3.0.0,>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery>=3.31.0->google-cloud-bigquery[bqstorage,pandas]>=3.31.0->-r kaggle-requirements.txt (line 17)) (2.4.3)\nRequirement already satisfied: google-resumable-media<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery>=3.31.0->google-cloud-bigquery[bqstorage,pandas]>=3.31.0->-r kaggle-requirements.txt (line 17)) (2.7.2)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery>=3.31.0->google-cloud-bigquery[bqstorage,pandas]>=3.31.0->-r kaggle-requirements.txt (line 17)) (2.9.0.post0)\nRequirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery>=3.31.0->google-cloud-bigquery[bqstorage,pandas]>=3.31.0->-r kaggle-requirements.txt (line 17)) (1.73.1)\nRequirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery>=3.31.0->google-cloud-bigquery[bqstorage,pandas]>=3.31.0->-r kaggle-requirements.txt (line 17)) (1.49.0rc1)\nCollecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery>=3.31.0->google-cloud-bigquery[bqstorage,pandas]>=3.31.0->-r kaggle-requirements.txt (line 17))\n  Downloading grpcio_status-1.75.1-py3-none-any.whl.metadata (1.1 kB)\nRequirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.11/dist-packages (from google-resumable-media<3.0.0,>=2.0.0->google-cloud-bigquery>=3.31.0->google-cloud-bigquery[bqstorage,pandas]>=3.31.0->-r kaggle-requirements.txt (line 17)) (1.7.1)\nINFO: pip is looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n  Downloading grpcio_status-1.75.0-py3-none-any.whl.metadata (1.1 kB)\n  Downloading grpcio_status-1.74.0-py3-none-any.whl.metadata (1.1 kB)\n  Downloading grpcio_status-1.73.1-py3-none-any.whl.metadata (1.1 kB)\n  Downloading grpcio_status-1.73.0-py3-none-any.whl.metadata (1.1 kB)\n  Downloading grpcio_status-1.72.2-py3-none-any.whl.metadata (1.1 kB)\n  Downloading grpcio_status-1.72.1-py3-none-any.whl.metadata (1.1 kB)\n  Downloading grpcio_status-1.71.2-py3-none-any.whl.metadata (1.1 kB)\nINFO: pip is still looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n  Downloading grpcio_status-1.71.0-py3-none-any.whl.metadata (1.1 kB)\n  Downloading grpcio_status-1.70.0-py3-none-any.whl.metadata (1.1 kB)\n  Downloading grpcio_status-1.69.0-py3-none-any.whl.metadata (1.1 kB)\n  Downloading grpcio_status-1.68.1-py3-none-any.whl.metadata (1.1 kB)\n  Downloading grpcio_status-1.68.0-py3-none-any.whl.metadata (1.1 kB)\nINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n  Downloading grpcio_status-1.67.1-py3-none-any.whl.metadata (1.1 kB)\n  Downloading grpcio_status-1.67.0-py3-none-any.whl.metadata (1.1 kB)\n  Downloading grpcio_status-1.66.2-py3-none-any.whl.metadata (1.1 kB)\n  Downloading grpcio_status-1.66.1-py3-none-any.whl.metadata (1.1 kB)\n  Downloading grpcio_status-1.66.0-py3-none-any.whl.metadata (1.1 kB)\n  Downloading grpcio_status-1.65.5-py3-none-any.whl.metadata (1.1 kB)\n  Downloading grpcio_status-1.65.4-py3-none-any.whl.metadata (1.1 kB)\n  Downloading grpcio_status-1.65.2-py3-none-any.whl.metadata (1.1 kB)\n  Downloading grpcio_status-1.65.1-py3-none-any.whl.metadata (1.1 kB)\n  Downloading grpcio_status-1.64.3-py3-none-any.whl.metadata (1.1 kB)\n  Downloading grpcio_status-1.64.1-py3-none-any.whl.metadata (1.1 kB)\n  Downloading grpcio_status-1.64.0-py3-none-any.whl.metadata (1.1 kB)\n  Downloading grpcio_status-1.63.2-py3-none-any.whl.metadata (1.1 kB)\n  Downloading grpcio_status-1.63.0-py3-none-any.whl.metadata (1.1 kB)\n  Downloading grpcio_status-1.62.3-py3-none-any.whl.metadata (1.3 kB)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery>=3.31.0->google-cloud-bigquery[bqstorage,pandas]>=3.31.0->-r kaggle-requirements.txt (line 17)) (1.17.0)\nRequirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna==3.6.1->-r kaggle-requirements.txt (line 7)) (1.3.10)\nRequirement already satisfied: pyarrow>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery[bqstorage,pandas]>=3.31.0->-r kaggle-requirements.txt (line 17)) (19.0.1)\nRequirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery[bqstorage,pandas]>=3.31.0->-r kaggle-requirements.txt (line 17)) (2.2.3)\nRequirement already satisfied: pandas-gbq>=0.26.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery[bqstorage,pandas]>=3.31.0->-r kaggle-requirements.txt (line 17)) (0.29.1)\nRequirement already satisfied: db-dtypes<2.0.0,>=1.0.4 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery[bqstorage,pandas]>=3.31.0->-r kaggle-requirements.txt (line 17)) (1.4.3)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich==13.7.1->-r kaggle-requirements.txt (line 19)) (0.1.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->optuna==3.6.1->-r kaggle-requirements.txt (line 7)) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->optuna==3.6.1->-r kaggle-requirements.txt (line 7)) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->optuna==3.6.1->-r kaggle-requirements.txt (line 7)) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->optuna==3.6.1->-r kaggle-requirements.txt (line 7)) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->optuna==3.6.1->-r kaggle-requirements.txt (line 7)) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->optuna==3.6.1->-r kaggle-requirements.txt (line 7)) (2.4.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->google-cloud-bigquery[bqstorage,pandas]>=3.31.0->-r kaggle-requirements.txt (line 17)) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->google-cloud-bigquery[bqstorage,pandas]>=3.31.0->-r kaggle-requirements.txt (line 17)) (2025.2)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from pandas-gbq>=0.26.1->google-cloud-bigquery[bqstorage,pandas]>=3.31.0->-r kaggle-requirements.txt (line 17)) (75.2.0)\nRequirement already satisfied: pydata-google-auth>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from pandas-gbq>=0.26.1->google-cloud-bigquery[bqstorage,pandas]>=3.31.0->-r kaggle-requirements.txt (line 17)) (1.9.1)\nRequirement already satisfied: google-auth-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from pandas-gbq>=0.26.1->google-cloud-bigquery[bqstorage,pandas]>=3.31.0->-r kaggle-requirements.txt (line 17)) (1.2.2)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib>=0.7.0->pandas-gbq>=0.26.1->google-cloud-bigquery[bqstorage,pandas]>=3.31.0->-r kaggle-requirements.txt (line 17)) (2.0.0)\nRequirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.7.0->pandas-gbq>=0.26.1->google-cloud-bigquery[bqstorage,pandas]>=3.31.0->-r kaggle-requirements.txt (line 17)) (3.3.1)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.3.0->optuna==3.6.1->-r kaggle-requirements.txt (line 7)) (3.2.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->geotorch==0.3.0->-r kaggle-requirements.txt (line 9)) (3.18.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->geotorch==0.3.0->-r kaggle-requirements.txt (line 9)) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->geotorch==0.3.0->-r kaggle-requirements.txt (line 9)) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->geotorch==0.3.0->-r kaggle-requirements.txt (line 9)) (2025.5.1)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.9->geotorch==0.3.0->-r kaggle-requirements.txt (line 9))\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.9->geotorch==0.3.0->-r kaggle-requirements.txt (line 9))\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.9->geotorch==0.3.0->-r kaggle-requirements.txt (line 9))\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.9->geotorch==0.3.0->-r kaggle-requirements.txt (line 9))\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.9->geotorch==0.3.0->-r kaggle-requirements.txt (line 9))\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.9->geotorch==0.3.0->-r kaggle-requirements.txt (line 9))\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.9->geotorch==0.3.0->-r kaggle-requirements.txt (line 9))\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.9->geotorch==0.3.0->-r kaggle-requirements.txt (line 9))\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.9->geotorch==0.3.0->-r kaggle-requirements.txt (line 9))\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->geotorch==0.3.0->-r kaggle-requirements.txt (line 9)) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->geotorch==0.3.0->-r kaggle-requirements.txt (line 9)) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->geotorch==0.3.0->-r kaggle-requirements.txt (line 9)) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.9->geotorch==0.3.0->-r kaggle-requirements.txt (line 9))\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->geotorch==0.3.0->-r kaggle-requirements.txt (line 9)) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->geotorch==0.3.0->-r kaggle-requirements.txt (line 9)) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.9->geotorch==0.3.0->-r kaggle-requirements.txt (line 9)) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.9->geotorch==0.3.0->-r kaggle-requirements.txt (line 9)) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->optuna==3.6.1->-r kaggle-requirements.txt (line 7)) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->optuna==3.6.1->-r kaggle-requirements.txt (line 7)) (2022.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->optuna==3.6.1->-r kaggle-requirements.txt (line 7)) (2024.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->optuna==3.6.1->-r kaggle-requirements.txt (line 7)) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->optuna==3.6.1->-r kaggle-requirements.txt (line 7)) (2024.2.0)\nRequirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest->stribor==0.1.0->-r kaggle-requirements.txt (line 11)) (2.1.0)\nRequirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest->stribor==0.1.0->-r kaggle-requirements.txt (line 11)) (1.6.0)\nDownloading mlflow_skinny-3.4.0-py3-none-any.whl (2.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n\u001b[?25hDownloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\nDownloading optuna-3.6.1-py3-none-any.whl (380 kB)\nDownloading geotorch-0.3.0-py3-none-any.whl (54 kB)\nDownloading reformer_pytorch-1.4.4-py3-none-any.whl (16 kB)\nDownloading stribor-0.1.0-py3-none-any.whl (54 kB)\nDownloading local_attention-1.9.0-py3-none-any.whl (8.2 kB)\nDownloading rich-13.7.1-py3-none-any.whl (240 kB)\nDownloading torchdiffeq-0.2.1-py3-none-any.whl (31 kB)\nDownloading google_api_core-2.26.0-py3-none-any.whl (162 kB)\nDownloading databricks_sdk-0.68.0-py3-none-any.whl (738 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m738.2/738.2 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n\u001b[?25hDownloading opentelemetry_api-1.38.0-py3-none-any.whl (65 kB)\nDownloading opentelemetry_proto-1.27.0-py3-none-any.whl (52 kB)\nDownloading opentelemetry_sdk-1.38.0-py3-none-any.whl (132 kB)\nDownloading opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl (207 kB)\nDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\nDownloading google_cloud_bigquery-3.38.0-py3-none-any.whl (259 kB)\nDownloading grpcio_status-1.62.3-py3-none-any.whl (14 kB)\nDownloading google_cloud_bigquery_storage-2.33.1-py3-none-any.whl (293 kB)\nDownloading google_cloud_automl-2.17.0-py3-none-any.whl (367 kB)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m  \u001b[33m0:00:04\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m6m0:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m6m0:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m  \u001b[33m0:00:09\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m  \u001b[33m0:00:06\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m92.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m89.5 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m101.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: product-key-memory, axial-positional-embedding\n\u001b[33m  DEPRECATION: Building 'product-key-memory' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'product-key-memory'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n\u001b[0m  Building wheel for product-key-memory (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for product-key-memory: filename=product_key_memory-0.1.10-py3-none-any.whl size=3058 sha256=ded82f4f75c213924d297ea32c2399271924c6a0718094be3dad44c328a773d9\n  Stored in directory: /root/.cache/pip/wheels/29/57/b2/a68319d3502491310896bcc07d93513707943fe48692c6975a\n\u001b[33m  DEPRECATION: Building 'axial-positional-embedding' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'axial-positional-embedding'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n\u001b[0m  Building wheel for axial-positional-embedding (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for axial-positional-embedding: filename=axial_positional_embedding-0.2.1-py3-none-any.whl size=2888 sha256=78be1edc190b713fe615b30dd43b002969582d917c13e0c6d74d9fcd8d26a211\n  Stored in directory: /root/.cache/pip/wheels/40/73/a5/19052fc842d96dcd53f9b447ea0ea0e9d3ea023bbf23359424\nSuccessfully built product-key-memory axial-positional-embedding\nInstalling collected packages: python-dotenv, protobuf, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, rich, opentelemetry-proto, opentelemetry-api, nvidia-cusparse-cu12, nvidia-cudnn-cu12, opentelemetry-semantic-conventions, nvidia-cusolver-cu12, grpcio-status, google-api-core, databricks-sdk, opentelemetry-sdk, torchdiffeq, product-key-memory, mlflow-skinny, local-attention, google-cloud-bigquery-storage, google-cloud-bigquery, google-cloud-automl, geotorch, axial-positional-embedding, reformer-pytorch, stribor, optuna\n\u001b[2K  Attempting uninstall: protobuf\n\u001b[2K    Found existing installation: protobuf 3.20.3\n\u001b[2K    Uninstalling protobuf-3.20.3:\n\u001b[2K      Successfully uninstalled protobuf-3.20.3━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/32\u001b[0m [protobuf]\n\u001b[2K  Attempting uninstall: nvidia-nvjitlink-cu12━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/32\u001b[0m [protobuf]\n\u001b[2K    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\u001b[0m \u001b[32m 1/32\u001b[0m [protobuf]\n\u001b[2K    Uninstalling nvidia-nvjitlink-cu12-12.5.82:━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/32\u001b[0m [protobuf]\n\u001b[2K      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82━━━━━━\u001b[0m \u001b[32m 2/32\u001b[0m [nvidia-nvjitlink-cu12]\n\u001b[2K  Attempting uninstall: nvidia-curand-cu12━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/32\u001b[0m [nvidia-nvjitlink-cu12]\n\u001b[2K    Found existing installation: nvidia-curand-cu12 10.3.6.82━━━━━\u001b[0m \u001b[32m 3/32\u001b[0m [nvidia-curand-cu12]\n\u001b[2K    Uninstalling nvidia-curand-cu12-10.3.6.82:━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/32\u001b[0m [nvidia-curand-cu12]\n\u001b[2K      Successfully uninstalled nvidia-curand-cu12-10.3.6.82━━━━━━━\u001b[0m \u001b[32m 3/32\u001b[0m [nvidia-curand-cu12]\n\u001b[2K  Attempting uninstall: nvidia-cufft-cu12━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/32\u001b[0m [nvidia-curand-cu12]\n\u001b[2K    Found existing installation: nvidia-cufft-cu12 11.2.3.61━━\u001b[0m \u001b[32m 3/32\u001b[0m [nvidia-curand-cu12]\n\u001b[2K    Uninstalling nvidia-cufft-cu12-11.2.3.61:━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/32\u001b[0m [nvidia-curand-cu12]\n\u001b[2K      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61━━━━━━━━\u001b[0m \u001b[32m 4/32\u001b[0m [nvidia-cufft-cu12]\n\u001b[2K  Attempting uninstall: nvidia-cuda-runtime-cu12━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/32\u001b[0m [nvidia-cufft-cu12]\n\u001b[2K    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82m \u001b[32m 4/32\u001b[0m [nvidia-cufft-cu12]\n\u001b[2K    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/32\u001b[0m [nvidia-cuda-runtime-cu12]\n\u001b[2K      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82[0m \u001b[32m 5/32\u001b[0m [nvidia-cuda-runtime-cu12]\n\u001b[2K  Attempting uninstall: nvidia-cuda-nvrtc-cu12━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/32\u001b[0m [nvidia-cuda-runtime-cu12]\n\u001b[2K    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82[0m \u001b[32m 5/32\u001b[0m [nvidia-cuda-runtime-cu12]\n\u001b[2K    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/32\u001b[0m [nvidia-cuda-runtime-cu12]\n\u001b[2K      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82━━━━━\u001b[0m \u001b[32m 6/32\u001b[0m [nvidia-cuda-nvrtc-cu12]\n\u001b[2K  Attempting uninstall: nvidia-cuda-cupti-cu12━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/32\u001b[0m [nvidia-cuda-nvrtc-cu12]\n\u001b[2K    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82[0m \u001b[32m 6/32\u001b[0m [nvidia-cuda-nvrtc-cu12]\n\u001b[2K    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/32\u001b[0m [nvidia-cuda-nvrtc-cu12]\n\u001b[2K      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82━━━━━\u001b[0m \u001b[32m 7/32\u001b[0m [nvidia-cuda-cupti-cu12]\n\u001b[2K  Attempting uninstall: nvidia-cublas-cu12━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/32\u001b[0m [nvidia-cuda-cupti-cu12]\n\u001b[2K    Found existing installation: nvidia-cublas-cu12 12.5.3.2━━\u001b[0m \u001b[32m 7/32\u001b[0m [nvidia-cuda-cupti-cu12]\n\u001b[2K    Uninstalling nvidia-cublas-cu12-12.5.3.2:━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/32\u001b[0m [nvidia-cuda-cupti-cu12]\n\u001b[2K      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2━━━━━━━━\u001b[0m \u001b[32m 8/32\u001b[0m [nvidia-cublas-cu12]\n\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/32\u001b[0m [nvidia-cublas-cu12]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"!pip install -f https://download.pytorch.org/whl/cu124 \\\n    torch==2.6.0+cu124 torchvision==0.21.0+cu124 torchaudio==2.6.0+cu124 \n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# HYPERPARAMETER TUNING WITH OPTUNA AND MLFLOW # ","metadata":{}},{"cell_type":"code","source":"!python scripts/run_kaggle_optuna.py \\\n    --data-root /kaggle/working/MasterThesis-1/data \\\n    --plan C:mimic:24 L:mimic:24 Q:mimic:24 S:mimic:24 \\\n    --trials 10 \\\n    --epochs 100 \\\n    --study-prefix mimic_all_icfld \\\n    --no-install\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T21:22:03.417584Z","iopub.execute_input":"2025-10-16T21:22:03.418235Z","iopub.status.idle":"2025-10-16T21:22:15.680240Z","shell.execute_reply.started":"2025-10-16T21:22:03.418202Z","shell.execute_reply":"2025-10-16T21:22:15.679562Z"}},"outputs":[{"name":"stdout","text":"[pip] Skipping dependency installation (--no-install).\n[data] Missing '/kaggle/working/MasterThesis-1/data/mimic'. Skipping symlink for 'mimic'.\n[fld] FLD reporter disabled; using base metrics (matches tPatchGNN).\n[train] Overriding epochs to 100.\n2025/10/16 21:22:06 INFO mlflow.tracking.fluent: Experiment with name 'mimic_all_icfld_optuna' does not exist. Creating a new experiment.\n[mlflow] Tracking to /kaggle/working/MasterThesis-1/mlruns (experiment='mimic_all_icfld_optuna', trainer='icfld').\n\n=== Study: mimic_all_icfld_C_mimic (history=24, trials=10) ===\n\u001b[32m[I 2025-10-16 21:22:06,046]\u001b[0m A new study created in memory with name: mimic_all_icfld_C_mimic\u001b[0m\n\u001b[33m[W 2025-10-16 21:22:15,286]\u001b[0m Trial 0 failed with parameters: {'latent_dim': 128, 'num_heads': 8, 'depth': 2, 'embed_per_head': 2} because of the following error: RuntimeError('Training failed (exit 1): Traceback (most recent call last):\\n  File \"/kaggle/working/MasterThesis-1/FLD_ICC/train_FLD_ICC.py\", line 424, in <module>\\n    data_obj = parse_datasets(pd_args, patch_ts=False)\\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/kaggle/working/MasterThesis-1/lib/parse_datasets.py\", line 35, in parse_datasets\\n    total_dataset = MIMIC(\\'../data/mimic/\\', n_samples = args.n, device = device)\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/kaggle/working/MasterThesis-1/lib/mimic.py\", line 16, in __init__\\n    self.process()\\n  File \"/kaggle/working/MasterThesis-1/lib/mimic.py\", line 37, in process\\n    full_data = pd.read_csv(filename, index_col=0)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\\n    return _read(filepath_or_buffer, kwds)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\", line 620, in _read\\n    parser = TextFileReader(filepath_or_buffer, **kwds)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\", line 1620, in __init__\\n    self._engine = self._make_engine(f, self.engine)\\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\", line 1880, in _make_engine\\n    self.handles = get_handle(\\n                   ^^^^^^^^^^^\\n  File \"/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\", line 873, in get_handle\\n    handle = open(\\n             ^^^^^\\nFileNotFoundError: [Errno 2] No such file or directory: \\'../data/mimic/raw/full_dataset.csv\\'\\n').\u001b[0m\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/kaggle/working/MasterThesis-1/scripts/optuna_icfld.py\", line 250, in objective\n    metrics = run_icfld_training(function, params, extra_args=extra_args)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/kaggle/working/MasterThesis-1/scripts/optuna_icfld.py\", line 173, in run_icfld_training\n    lines = _run_subprocess(cmd, cwd=ICFLD_TRAIN_SCRIPT.parent)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/kaggle/working/MasterThesis-1/scripts/optuna_icfld.py\", line 78, in _run_subprocess\n    raise RuntimeError(f\"Training failed (exit {result.returncode}): {result.stderr}\")\nRuntimeError: Training failed (exit 1): Traceback (most recent call last):\n  File \"/kaggle/working/MasterThesis-1/FLD_ICC/train_FLD_ICC.py\", line 424, in <module>\n    data_obj = parse_datasets(pd_args, patch_ts=False)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/kaggle/working/MasterThesis-1/lib/parse_datasets.py\", line 35, in parse_datasets\n    total_dataset = MIMIC('../data/mimic/', n_samples = args.n, device = device)\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/kaggle/working/MasterThesis-1/lib/mimic.py\", line 16, in __init__\n    self.process()\n  File \"/kaggle/working/MasterThesis-1/lib/mimic.py\", line 37, in process\n    full_data = pd.read_csv(filename, index_col=0)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n    return _read(filepath_or_buffer, kwds)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\", line 620, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\", line 1620, in __init__\n    self._engine = self._make_engine(f, self.engine)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\", line 1880, in _make_engine\n    self.handles = get_handle(\n                   ^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\", line 873, in get_handle\n    handle = open(\n             ^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: '../data/mimic/raw/full_dataset.csv'\n\n\u001b[33m[W 2025-10-16 21:22:15,287]\u001b[0m Trial 0 failed with value None.\u001b[0m\nTraceback (most recent call last):\n  File \"/kaggle/working/MasterThesis-1/scripts/run_kaggle_optuna.py\", line 271, in <module>\n    main()\n  File \"/kaggle/working/MasterThesis-1/scripts/run_kaggle_optuna.py\", line 261, in main\n    run_studies(\n  File \"/kaggle/working/MasterThesis-1/scripts/run_kaggle_optuna.py\", line 145, in run_studies\n    study.optimize(\n  File \"/usr/local/lib/python3.11/dist-packages/optuna/study/study.py\", line 451, in optimize\n    _optimize(\n  File \"/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\", line 62, in _optimize\n    _optimize_sequential(\n  File \"/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\", line 159, in _optimize_sequential\n    frozen_trial = _run_trial(study, func, catch)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\", line 247, in _run_trial\n    raise func_err\n  File \"/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n    value_or_values = func(trial)\n                      ^^^^^^^^^^^\n  File \"/kaggle/working/MasterThesis-1/scripts/optuna_icfld.py\", line 250, in objective\n    metrics = run_icfld_training(function, params, extra_args=extra_args)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/kaggle/working/MasterThesis-1/scripts/optuna_icfld.py\", line 173, in run_icfld_training\n    lines = _run_subprocess(cmd, cwd=ICFLD_TRAIN_SCRIPT.parent)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/kaggle/working/MasterThesis-1/scripts/optuna_icfld.py\", line 78, in _run_subprocess\n    raise RuntimeError(f\"Training failed (exit {result.returncode}): {result.stderr}\")\nRuntimeError: Training failed (exit 1): Traceback (most recent call last):\n  File \"/kaggle/working/MasterThesis-1/FLD_ICC/train_FLD_ICC.py\", line 424, in <module>\n    data_obj = parse_datasets(pd_args, patch_ts=False)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/kaggle/working/MasterThesis-1/lib/parse_datasets.py\", line 35, in parse_datasets\n    total_dataset = MIMIC('../data/mimic/', n_samples = args.n, device = device)\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/kaggle/working/MasterThesis-1/lib/mimic.py\", line 16, in __init__\n    self.process()\n  File \"/kaggle/working/MasterThesis-1/lib/mimic.py\", line 37, in process\n    full_data = pd.read_csv(filename, index_col=0)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n    return _read(filepath_or_buffer, kwds)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\", line 620, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\", line 1620, in __init__\n    self._engine = self._make_engine(f, self.engine)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\", line 1880, in _make_engine\n    self.handles = get_handle(\n                   ^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\", line 873, in get_handle\n    handle = open(\n             ^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: '../data/mimic/raw/full_dataset.csv'\n\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"!python scripts/run_kaggle_optuna.py \\\n    --data-root /kaggle/working/MasterThesis-1/data \\\n    --plan C:physionet:24 L:physionet:24 Q:physionet:24 S:physionet:24 \\\n    --trials 20 \\\n    --epochs 100 \\\n    --study-prefix physionet_all \\\n    --no-install\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!python scripts/optuna_ushcn.py \\\n  --trainer icfld \\\n  --functions Q S \\\n  --trials 20 \\\n  --study-prefix ushcn_icfld\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !python scripts/run_kaggle_optuna.py \\\n#     --data-root /kaggle/working/MasterThesis-1/data \\\n#     --plan C:activity:3000 L:activity:3000 Q:activity:3000 S:activity:3000 \\\n#     --trials 20 \\\n#     --epochs 100 \\\n#     --study-prefix activity_all \\\n#     --no-install\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !zip -r mlruns.zip mlruns","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# FULL RUN IC-FLD","metadata":{}},{"cell_type":"code","source":"# %%bash\n# cd /kaggle/working/MasterThesis-1\n# chmod +x scripts/run_best_hparams.sh\n# ./scripts/run_best_hparams.sh best_hparams_sample.json\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T16:33:15.365240Z","iopub.execute_input":"2025-10-16T16:33:15.366071Z","iopub.status.idle":"2025-10-16T16:33:15.369543Z","shell.execute_reply.started":"2025-10-16T16:33:15.366037Z","shell.execute_reply":"2025-10-16T16:33:15.368732Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"%%bash\ncd /kaggle/working/MasterThesis-1\nchmod +x scripts/run_best_hparams.sh\n./scripts/run_best_hparams.sh best_hparams_ushcn.json\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T16:38:44.759791Z","iopub.execute_input":"2025-10-16T16:38:44.760341Z","iopub.status.idle":"2025-10-16T16:43:38.083166Z","shell.execute_reply.started":"2025-10-16T16:38:44.760319Z","shell.execute_reply":"2025-10-16T16:43:38.082556Z"}},"outputs":[{"name":"stdout","text":"[run] ushcn/C via icfld\npython train_FLD_ICC.py -d ushcn -fn C --latent-dim 128 --embedding-dim 64 --num-heads 2 --depth 2 --batch-size 128 --epochs 1000 --early-stop 10 --lr 0.0001 --wd 0.001 --observation-time 24 --tbon --logdir runs/ushcn_C_icfld\n[TensorBoard] logging to: runs/ushcn_ushcn_C_icfld_1760632743\nTotal records: 1114\nDataset n_samples: 1114 668 223 223\nTest record ids (first 20): [886, 101, 1120, 730, 291, 875, 958, 260, 128, 1043, 620, 88, 1005, 872, 617, 538, 508, 44, 273, 817]\nTest record ids (last 20): [982, 275, 991, 997, 66, 801, 67, 942, 12, 361, 555, 710, 333, 1017, 851, 184, 882, 509, 726, 587]\ndata_max: tensor([37.2551, 36.6691, 38.2520,  3.0401,  2.9104], device='cuda:0')\ndata_min: tensor([-0.3057, -0.1280, -0.1738, -3.8821, -4.1854], device='cuda:0')\ntime_max: tensor(48., device='cuda:0')\nDataset n_samples after time split: 26736 16032 5352 5352\nPID, device: 153 cuda\nDataset=ushcn, INPUT_DIM=5, history=24\nn_train_batches: 126\n- Epoch 001 | train_loss(one-batch): nan | val_loss: nan | val_mse: nan | val_rmse: nan | val_mae: nan | time: 5.83s\n- Epoch 002 | train_loss(one-batch): nan | val_loss: nan | val_mse: nan | val_rmse: nan | val_mae: nan | time: 5.39s\n- Epoch 003 | train_loss(one-batch): nan | val_loss: nan | val_mse: nan | val_rmse: nan | val_mae: nan | time: 5.31s\n- Epoch 004 | train_loss(one-batch): nan | val_loss: nan | val_mse: nan | val_rmse: nan | val_mae: nan | time: 5.34s\n- Epoch 005 | train_loss(one-batch): nan | val_loss: nan | val_mse: nan | val_rmse: nan | val_mae: nan | time: 5.31s\n- Epoch 006 | train_loss(one-batch): nan | val_loss: nan | val_mse: nan | val_rmse: nan | val_mae: nan | time: 5.35s\n- Epoch 007 | train_loss(one-batch): nan | val_loss: nan | val_mse: nan | val_rmse: nan | val_mae: nan | time: 5.34s\n- Epoch 008 | train_loss(one-batch): nan | val_loss: nan | val_mse: nan | val_rmse: nan | val_mae: nan | time: 5.37s\n- Epoch 009 | train_loss(one-batch): nan | val_loss: nan | val_mse: nan | val_rmse: nan | val_mae: nan | time: 5.33s\n- Epoch 010 | train_loss(one-batch): nan | val_loss: nan | val_mse: nan | val_rmse: nan | val_mae: nan | time: 5.34s\nEarly stopping at epoch 10 (no improvement for 10 epochs).\nBest val MSE: inf @ epoch 0\nSaved best: /kaggle/working/MasterThesis-1/FLD_ICC/saved_models/ICFLD-ushcn-536340.best.pt\nSaved latest: /kaggle/working/MasterThesis-1/FLD_ICC/saved_models/ICFLD-ushcn-536340.latest.pt\n{\"best_epoch\": 0.0}\n[run] ushcn/L via icfld\npython train_FLD_ICC.py -d ushcn -fn L --latent-dim 128 --embedding-dim 64 --num-heads 2 --depth 2 --batch-size 128 --epochs 1000 --early-stop 10 --lr 0.0001 --wd 0.001 --observation-time 24 --tbon --logdir runs/ushcn_L_icfld\n[TensorBoard] logging to: runs/ushcn_ushcn_L_icfld_1760632814\nTotal records: 1114\nDataset n_samples: 1114 668 223 223\nTest record ids (first 20): [886, 101, 1120, 730, 291, 875, 958, 260, 128, 1043, 620, 88, 1005, 872, 617, 538, 508, 44, 273, 817]\nTest record ids (last 20): [982, 275, 991, 997, 66, 801, 67, 942, 12, 361, 555, 710, 333, 1017, 851, 184, 882, 509, 726, 587]\ndata_max: tensor([37.2551, 36.6691, 38.2520,  3.0401,  2.9104], device='cuda:0')\ndata_min: tensor([-0.3057, -0.1280, -0.1738, -3.8821, -4.1854], device='cuda:0')\ntime_max: tensor(48., device='cuda:0')\nDataset n_samples after time split: 26736 16032 5352 5352\nPID, device: 169 cuda\nDataset=ushcn, INPUT_DIM=5, history=24\nn_train_batches: 126\n- Epoch 001 | train_loss(one-batch): nan | val_loss: nan | val_mse: nan | val_rmse: nan | val_mae: nan | time: 6.04s\n- Epoch 002 | train_loss(one-batch): nan | val_loss: nan | val_mse: nan | val_rmse: nan | val_mae: nan | time: 5.50s\n- Epoch 003 | train_loss(one-batch): nan | val_loss: nan | val_mse: nan | val_rmse: nan | val_mae: nan | time: 5.42s\n- Epoch 004 | train_loss(one-batch): nan | val_loss: nan | val_mse: nan | val_rmse: nan | val_mae: nan | time: 5.44s\n- Epoch 005 | train_loss(one-batch): nan | val_loss: nan | val_mse: nan | val_rmse: nan | val_mae: nan | time: 5.41s\n- Epoch 006 | train_loss(one-batch): nan | val_loss: nan | val_mse: nan | val_rmse: nan | val_mae: nan | time: 5.42s\n- Epoch 007 | train_loss(one-batch): nan | val_loss: nan | val_mse: nan | val_rmse: nan | val_mae: nan | time: 5.37s\n- Epoch 008 | train_loss(one-batch): nan | val_loss: nan | val_mse: nan | val_rmse: nan | val_mae: nan | time: 5.43s\n- Epoch 009 | train_loss(one-batch): nan | val_loss: nan | val_mse: nan | val_rmse: nan | val_mae: nan | time: 5.39s\n- Epoch 010 | train_loss(one-batch): nan | val_loss: nan | val_mse: nan | val_rmse: nan | val_mae: nan | time: 5.43s\nEarly stopping at epoch 10 (no improvement for 10 epochs).\nBest val MSE: inf @ epoch 0\nSaved best: /kaggle/working/MasterThesis-1/FLD_ICC/saved_models/ICFLD-ushcn-8841599.best.pt\nSaved latest: /kaggle/working/MasterThesis-1/FLD_ICC/saved_models/ICFLD-ushcn-8841599.latest.pt\n{\"best_epoch\": 0.0}\n[run] ushcn/Q via icfld\npython train_FLD_ICC.py -d ushcn -fn Q --latent-dim 128 --embedding-dim 64 --num-heads 2 --depth 2 --batch-size 128 --epochs 1000 --early-stop 10 --lr 0.0001 --wd 0.001 --observation-time 24 --tbon --logdir runs/ushcn_Q_icfld\n[TensorBoard] logging to: runs/ushcn_ushcn_Q_icfld_1760632884\nTotal records: 1114\nDataset n_samples: 1114 668 223 223\nTest record ids (first 20): [886, 101, 1120, 730, 291, 875, 958, 260, 128, 1043, 620, 88, 1005, 872, 617, 538, 508, 44, 273, 817]\nTest record ids (last 20): [982, 275, 991, 997, 66, 801, 67, 942, 12, 361, 555, 710, 333, 1017, 851, 184, 882, 509, 726, 587]\ndata_max: tensor([37.2551, 36.6691, 38.2520,  3.0401,  2.9104], device='cuda:0')\ndata_min: tensor([-0.3057, -0.1280, -0.1738, -3.8821, -4.1854], device='cuda:0')\ntime_max: tensor(48., device='cuda:0')\nDataset n_samples after time split: 26736 16032 5352 5352\nPID, device: 185 cuda\nDataset=ushcn, INPUT_DIM=5, history=24\nn_train_batches: 126\n- Epoch 001 | train_loss(one-batch): nan | val_loss: nan | val_mse: nan | val_rmse: nan | val_mae: nan | time: 6.03s\n- Epoch 002 | train_loss(one-batch): nan | val_loss: nan | val_mse: nan | val_rmse: nan | val_mae: nan | time: 5.49s\n- Epoch 003 | train_loss(one-batch): nan | val_loss: nan | val_mse: nan | val_rmse: nan | val_mae: nan | time: 5.46s\n- Epoch 004 | train_loss(one-batch): nan | val_loss: nan | val_mse: nan | val_rmse: nan | val_mae: nan | time: 5.47s\n- Epoch 005 | train_loss(one-batch): nan | val_loss: nan | val_mse: nan | val_rmse: nan | val_mae: nan | time: 5.43s\n- Epoch 006 | train_loss(one-batch): nan | val_loss: nan | val_mse: nan | val_rmse: nan | val_mae: nan | time: 5.47s\n- Epoch 007 | train_loss(one-batch): nan | val_loss: nan | val_mse: nan | val_rmse: nan | val_mae: nan | time: 5.46s\n- Epoch 008 | train_loss(one-batch): nan | val_loss: nan | val_mse: nan | val_rmse: nan | val_mae: nan | time: 5.47s\n- Epoch 009 | train_loss(one-batch): nan | val_loss: nan | val_mse: nan | val_rmse: nan | val_mae: nan | time: 5.44s\n- Epoch 010 | train_loss(one-batch): nan | val_loss: nan | val_mse: nan | val_rmse: nan | val_mae: nan | time: 5.46s\nEarly stopping at epoch 10 (no improvement for 10 epochs).\nBest val MSE: inf @ epoch 0\nSaved best: /kaggle/working/MasterThesis-1/FLD_ICC/saved_models/ICFLD-ushcn-4978772.best.pt\nSaved latest: /kaggle/working/MasterThesis-1/FLD_ICC/saved_models/ICFLD-ushcn-4978772.latest.pt\n{\"best_epoch\": 0.0}\n[run] ushcn/S via icfld\npython train_FLD_ICC.py -d ushcn -fn S --latent-dim 128 --embedding-dim 64 --num-heads 2 --depth 2 --batch-size 128 --epochs 1000 --early-stop 10 --lr 0.0001 --wd 0.001 --observation-time 24 --tbon --logdir runs/ushcn_S_icfld\n[TensorBoard] logging to: runs/ushcn_ushcn_S_icfld_1760632954\nTotal records: 1114\nDataset n_samples: 1114 668 223 223\nTest record ids (first 20): [886, 101, 1120, 730, 291, 875, 958, 260, 128, 1043, 620, 88, 1005, 872, 617, 538, 508, 44, 273, 817]\nTest record ids (last 20): [982, 275, 991, 997, 66, 801, 67, 942, 12, 361, 555, 710, 333, 1017, 851, 184, 882, 509, 726, 587]\ndata_max: tensor([37.2551, 36.6691, 38.2520,  3.0401,  2.9104], device='cuda:0')\ndata_min: tensor([-0.3057, -0.1280, -0.1738, -3.8821, -4.1854], device='cuda:0')\ntime_max: tensor(48., device='cuda:0')\nDataset n_samples after time split: 26736 16032 5352 5352\nPID, device: 201 cuda\nDataset=ushcn, INPUT_DIM=5, history=24\nn_train_batches: 126\n- Epoch 001 | train_loss(one-batch): nan | val_loss: nan | val_mse: nan | val_rmse: nan | val_mae: nan | time: 5.99s\n- Epoch 002 | train_loss(one-batch): nan | val_loss: nan | val_mse: nan | val_rmse: nan | val_mae: nan | time: 5.42s\n- Epoch 003 | train_loss(one-batch): nan | val_loss: nan | val_mse: nan | val_rmse: nan | val_mae: nan | time: 5.39s\n- Epoch 004 | train_loss(one-batch): nan | val_loss: nan | val_mse: nan | val_rmse: nan | val_mae: nan | time: 5.46s\n- Epoch 005 | train_loss(one-batch): nan | val_loss: nan | val_mse: nan | val_rmse: nan | val_mae: nan | time: 5.41s\n- Epoch 006 | train_loss(one-batch): nan | val_loss: nan | val_mse: nan | val_rmse: nan | val_mae: nan | time: 5.43s\n- Epoch 007 | train_loss(one-batch): nan | val_loss: nan | val_mse: nan | val_rmse: nan | val_mae: nan | time: 5.41s\n- Epoch 008 | train_loss(one-batch): nan | val_loss: nan | val_mse: nan | val_rmse: nan | val_mae: nan | time: 5.43s\n- Epoch 009 | train_loss(one-batch): nan | val_loss: nan | val_mse: nan | val_rmse: nan | val_mae: nan | time: 5.39s\n- Epoch 010 | train_loss(one-batch): nan | val_loss: nan | val_mse: nan | val_rmse: nan | val_mae: nan | time: 5.42s\nEarly stopping at epoch 10 (no improvement for 10 epochs).\nBest val MSE: inf @ epoch 0\nSaved best: /kaggle/working/MasterThesis-1/FLD_ICC/saved_models/ICFLD-ushcn-4991958.best.pt\nSaved latest: /kaggle/working/MasterThesis-1/FLD_ICC/saved_models/ICFLD-ushcn-4991958.latest.pt\n{\"best_epoch\": 0.0}\n","output_type":"stream"},{"name":"stderr","text":"2025-10-16 16:38:53.828077: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1760632734.006106     153 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1760632734.058215     153 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-10-16 16:40:11.631263: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1760632811.658899     169 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1760632811.665783     169 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-10-16 16:41:21.867180: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1760632881.889718     185 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1760632881.896656     185 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-10-16 16:42:32.421640: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1760632952.444148     201 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1760632952.450932     201 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"!python FLD_ICC/train_FLD_ICC_ushcn.py \\\n    -d ushcn -fn C \\\n    -ld 128 -ed 64 -nh 2 -dp 2 \\\n    -bs 128 --epochs 1000 --early-stop 30 \\\n    --lr 1e-4 --wd 1e-3 \\\n    --tbon --logdir runs/ushcn_C_icfld\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%bash\ncd /kaggle/working/MasterThesis-1\nchmod +x scripts/run_best_hparams.sh\n./scripts/run_best_hparams.sh best_hparams_mimic.json\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T16:58:50.217857Z","iopub.execute_input":"2025-10-16T16:58:50.218481Z","iopub.status.idle":"2025-10-16T18:39:36.299090Z","shell.execute_reply.started":"2025-10-16T16:58:50.218456Z","shell.execute_reply":"2025-10-16T18:39:36.298307Z"}},"outputs":[{"name":"stdout","text":"Process is interrupted.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"%%bash\ncd /kaggle/working/MasterThesis-1\nzip -r saved_models_and_results.zip FLD_ICC/saved_models FLD_ICC/results FLD_ICC/saved_models FLD_ICC/runs\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T18:39:38.974100Z","iopub.execute_input":"2025-10-16T18:39:38.974820Z","iopub.status.idle":"2025-10-16T18:39:39.096710Z","shell.execute_reply.started":"2025-10-16T18:39:38.974794Z","shell.execute_reply":"2025-10-16T18:39:39.095980Z"}},"outputs":[{"name":"stdout","text":"  adding: FLD_ICC/saved_models/ (stored 0%)\n  adding: FLD_ICC/saved_models/ICFLD-mimic-6230510.latest.pt (deflated 9%)\n  adding: FLD_ICC/saved_models/ICFLD-ushcn-4991958.latest.pt (deflated 98%)\n  adding: FLD_ICC/saved_models/ICFLD-mimic-3288735.latest.pt (deflated 9%)\n  adding: FLD_ICC/saved_models/ICFLD-mimic-6230510.best.pt (deflated 9%)\n  adding: FLD_ICC/saved_models/ICFLD-mimic-8869793.best.pt (deflated 9%)\n  adding: FLD_ICC/saved_models/ICFLD-mimic-3288735.best.pt (deflated 9%)\n  adding: FLD_ICC/saved_models/ICFLD-mimic-8869793.latest.pt (deflated 9%)\n  adding: FLD_ICC/saved_models/ICFLD-ushcn-8841599.latest.pt (deflated 98%)\n  adding: FLD_ICC/saved_models/ICFLD-ushcn-536340.latest.pt (deflated 98%)\n  adding: FLD_ICC/saved_models/ICFLD-ushcn-4978772.latest.pt (deflated 98%)\n  adding: FLD_ICC/results/ (stored 0%)\n  adding: FLD_ICC/results/training_results.csv (deflated 60%)\n  adding: FLD_ICC/results/training_results.xlsx (deflated 10%)\n  adding: FLD_ICC/runs/ (stored 0%)\n  adding: FLD_ICC/runs/ushcn_ushcn_L_icfld_1760632814/ (stored 0%)\n  adding: FLD_ICC/runs/ushcn_ushcn_L_icfld_1760632814/events.out.tfevents.1760632814.e90bf2054917.169.0 (deflated 68%)\n  adding: FLD_ICC/runs/ushcn_ushcn_S_icfld_1760632954/ (stored 0%)\n  adding: FLD_ICC/runs/ushcn_ushcn_S_icfld_1760632954/events.out.tfevents.1760632954.e90bf2054917.201.0 (deflated 68%)\n  adding: FLD_ICC/runs/mimic_mimic_C_icfld_1760633937/ (stored 0%)\n  adding: FLD_ICC/runs/mimic_mimic_C_icfld_1760633937/events.out.tfevents.1760633937.e90bf2054917.221.0 (deflated 71%)\n  adding: FLD_ICC/runs/ushcn_ushcn_C_icfld_1760632743/ (stored 0%)\n  adding: FLD_ICC/runs/ushcn_ushcn_C_icfld_1760632743/events.out.tfevents.1760632743.e90bf2054917.153.0 (deflated 68%)\n  adding: FLD_ICC/runs/mimic_mimic_Q_icfld_1760638491/ (stored 0%)\n  adding: FLD_ICC/runs/mimic_mimic_Q_icfld_1760638491/events.out.tfevents.1760638491.e90bf2054917.253.0 (deflated 71%)\n  adding: FLD_ICC/runs/mimic_mimic_L_icfld_1760636766/ (stored 0%)\n  adding: FLD_ICC/runs/mimic_mimic_L_icfld_1760636766/events.out.tfevents.1760636766.e90bf2054917.237.0 (deflated 71%)\n  adding: FLD_ICC/runs/mimic_mimic_S_icfld_1760639885/ (stored 0%)\n  adding: FLD_ICC/runs/mimic_mimic_S_icfld_1760639885/events.out.tfevents.1760639885.e90bf2054917.269.0 (deflated 9%)\n  adding: FLD_ICC/runs/ushcn_ushcn_Q_icfld_1760632884/ (stored 0%)\n  adding: FLD_ICC/runs/ushcn_ushcn_Q_icfld_1760632884/events.out.tfevents.1760632884.e90bf2054917.185.0 (deflated 68%)\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# %reload_ext tensorboard\n# %tensorboard --logdir /kaggle/working/MasterThesis-1/runs\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T15:49:47.206588Z","iopub.execute_input":"2025-10-16T15:49:47.206860Z","iopub.status.idle":"2025-10-16T15:49:53.762503Z","shell.execute_reply.started":"2025-10-16T15:49:47.206840Z","shell.execute_reply":"2025-10-16T15:49:53.761753Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"\n        (async () => {\n            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n            url.searchParams.set('tensorboardColab', 'true');\n            const iframe = document.createElement('iframe');\n            iframe.src = url;\n            iframe.setAttribute('width', '100%');\n            iframe.setAttribute('height', '800');\n            iframe.setAttribute('frameborder', 0);\n            document.body.appendChild(iframe);\n        })();\n    "},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}